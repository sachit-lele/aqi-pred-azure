name: Trigger Batch Inference

# Allow the workflow to be manually triggered
on:
  workflow_dispatch:

jobs:
  run-batch-inference:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout the repository code
      - name: Checkout Repository
        uses: actions/checkout@v3

      # 2. Setup Python environment
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'  # Specify the Python version

      # 3. Azure Login
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}  # Ensure you have set this secret

      # 4. Install Azure Machine Learning extension
      - name: Install Azure ML Extension
        run: |
          az extension add --name ml

      # 5. Install project dependencies
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install python-dotenv azure-ai-ml azureml-core pandas numpy scikit-learn azureml-dataset-runtime pip install azureml-pipeline

      # 6. Configure Azure ML Workspace
      - name: Configure Azure ML Workspace
        run: |
            az configure --defaults group=myResource workspace=myWorkSpace

      # 7. Run Batch Inference Script
      - name: Run Batch Inference
        run: |
          python src/model/inference.py
          # Adjust the path if your script is located elsewhere


    
      # 8. (Optional) Upload Predictions to GitHub Artifacts or Azure Blob Storage
      # If you wish to upload the predictions as artifacts, uncomment the following steps
      # - name: Upload Predictions as Artifact
      #   uses: actions/upload-artifact@v3
      #   with:
      #     name: predictions
      #     path: src/data/predictions.csv  # Adjust the path to your predictions file

      # If your batch_inference.py already handles uploading to Azure Blob Storage, you can omit the above step.